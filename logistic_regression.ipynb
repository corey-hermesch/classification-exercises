{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff160fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import acquire as acq\n",
    "import prepare as prep\n",
    "import my_model as m\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd8eaa2",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "In these exercises, we'll continue working with the titanic dataset and building logistic regression models. Throughout this exercise, be sure you are training, evaluation, and comparing models on the train and validate datasets. The test dataset should only be used for your final model.\n",
    "\n",
    "For all of the models you create, choose a threshold that optimizes for accuracy.\n",
    "\n",
    "Create a new notebook, logistic_regression, use it to answer the following questions:\n",
    "\n",
    "1. Create a model that includes only age, fare, and pclass. Does this model perform better than your baseline?\n",
    "\n",
    "2. Include sex in your model as well. Note that you'll need to encode or create a dummy variable of this feature before including it in a model.\n",
    "\n",
    "3. Try out other combinations of features and models.\n",
    "\n",
    "4. Use you best 3 models to predict and evaluate on your validate sample.\n",
    "\n",
    "5. Choose you best model from the validation performation, and evaluate it on the test dataset. How do the performance metrics compare to validate? to train?\n",
    "\n",
    "- Bonus1 How do different strategies for handling the missing values in the age column affect model performance?\n",
    "\n",
    "- Bonus2: How do different strategies for encoding sex affect model performance?\n",
    "\n",
    "- Bonus3: scikit-learn's LogisticRegression classifier is actually applying a regularization penalty to the coefficients by default. This penalty causes the magnitude of the coefficients in the resulting model to be smaller than they otherwise would be. This value can be modified with the C hyper parameter. Small values of C correspond to a larger penalty, and large values of C correspond to a smaller penalty.\n",
    "\n",
    "    - Try out the following values for C and note how the coefficients and the model's performance on both the dataset it was trained on and on the validate split are affected. C=.01,.1,1,10,100,1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78913020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv file found and read\n"
     ]
    }
   ],
   "source": [
    "df = acq.get_titanic_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1c08dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Series name: age\n",
      "Non-Null Count  Dtype  \n",
      "--------------  -----  \n",
      "714 non-null    float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 7.1 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "177"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.age.info()\n",
    "# there are 177 null values in age. This time around, I will keep age and use SimpleImputer to impute values\n",
    "891-714"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32caf349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a second prepare function to keep age\n",
    "def prep_titanic_2(df):\n",
    "    \"\"\"\n",
    "    This function will\n",
    "    - take in the titanic dataframe\n",
    "    - clean it up \n",
    "        -- remove useless columns passenger_id, class, embark_town, deck\n",
    "        -- NOTE: keeping the age column\n",
    "        -- tack on dummies columns for 'pclass', 'sex', 'embarked'\n",
    "    - returns cleaned up dataframe\n",
    "    \"\"\"\n",
    "    df = df.drop(columns=['passenger_id', 'class', 'embark_town', 'deck'])\n",
    "    df.embarked = df.embarked.fillna('S')\n",
    "    dummies_df = pd.get_dummies(df[['sex','embarked']], drop_first=True)\n",
    "    new_df = pd.concat([df, dummies_df], axis=1)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c3e5495",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prep.prep_titanic_2(df) # _2 keeps age\n",
    "df = prep.prep_titanic_for_model(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3dceb37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>alone</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embarked_Q</th>\n",
       "      <th>embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass   age  sibsp  parch     fare  alone  sex_male  embarked_Q  \\\n",
       "0         0       3  22.0      1      0   7.2500      0         1           0   \n",
       "1         1       1  38.0      1      0  71.2833      0         0           0   \n",
       "2         1       3  26.0      0      0   7.9250      1         0           0   \n",
       "3         1       1  35.0      1      0  53.1000      0         0           0   \n",
       "4         0       3  35.0      0      0   8.0500      1         1           0   \n",
       "\n",
       "   embarked_S  \n",
       "0           1  \n",
       "1           0  \n",
       "2           1  \n",
       "3           1  \n",
       "4           1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "480c5151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared df: (891, 10)\n",
      "\n",
      "Train: (534, 10)\n",
      "Validate: (178, 10)\n",
      "Test: (179, 10)\n"
     ]
    }
   ],
   "source": [
    "target = 'survived'\n",
    "train, validate, test = prep.split_function(df, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae05664a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'll use median as the strategy to fill nan values in age\n",
    "# this function now in prepare\n",
    "def impute_feature(train, validate, test, feature='age', strat='median'):\n",
    "    \"\"\"\n",
    "    This function will\n",
    "    - take in train, validate, test dfs\n",
    "    - take in a string which is the column name that has nan values\n",
    "        -- default is 'age' (built off titanic df)\n",
    "    - take in a string which is the strategy to impute values\n",
    "        -- default is 'median'\n",
    "    - impute nan values in the feature(age) column and fill with new values\n",
    "    - return train, validate, test with imputed values\n",
    "    \"\"\"\n",
    "    imputer = SimpleImputer(missing_values=np.nan, strategy=strat)\n",
    "    imputer = imputer.fit(train[[feature]])\n",
    "    train[[feature]] = imputer.transform(train[[feature]])\n",
    "    validate[[feature]] = imputer.transform(validate[[feature]])\n",
    "    test[[feature]] = imputer.transform(test[[feature]])\n",
    "    \n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18b20504",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = prep.impute_feature(train, validate, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "522922d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>alone</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embarked_Q</th>\n",
       "      <th>embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>55.9000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>27.9000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20.2125</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>59.4000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>31.2750</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived  pclass   age  sibsp  parch     fare  alone  sex_male  \\\n",
       "577         1       1  39.0      1      0  55.9000      0         0   \n",
       "63          0       3   4.0      3      2  27.9000      0         1   \n",
       "424         0       3  18.0      1      1  20.2125      0         1   \n",
       "513         1       1  54.0      1      0  59.4000      0         0   \n",
       "610         0       3  39.0      1      5  31.2750      0         0   \n",
       "\n",
       "     embarked_Q  embarked_S  \n",
       "577           0           1  \n",
       "63            0           1  \n",
       "424           0           1  \n",
       "513           0           0  \n",
       "610           0           1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9577f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_validate, X_test, y_train, y_validate, y_test, baseline_accuracy = (\n",
    "    m.get_X_y_baseline(train, validate, test, target)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "556d7a53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6161048689138576"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b148d7c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX\n",
      "          0_predicted  1_predicted\n",
      "0_actual          282           47\n",
      "1_actual           60          145\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.86      0.84       329\n",
      "           1       0.76      0.71      0.73       205\n",
      "\n",
      "    accuracy                           0.80       534\n",
      "   macro avg       0.79      0.78      0.79       534\n",
      "weighted avg       0.80      0.80      0.80       534\n",
      "\n",
      "Accuracy: 0.799625468164794\n",
      "\n",
      "True Positive Rate/Sensitivity/Recall/Power: 0.7073170731707317\n",
      "False Positive Rate/False Alarm Ratio/Fall-out: 0.14285714285714285\n",
      "True Negative Rate/Specificity/Selectivity: 0.8571428571428571\n",
      "False Negative Rate/Miss Rate: 0.2926829268292683\n",
      "\n",
      "Precision/PPV: 0.7552083333333334\n",
      "F1 Score: 0.730478589420655\n",
      "\n",
      "Support (0): 205\n",
      "Support (1): 329\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(282, 47, 60, 145)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first send in everything. - make/fit/use the thing\n",
    "logit1 = LogisticRegression()\n",
    "logit1.fit(X_train, y_train)\n",
    "y_pred1 = logit1.predict(X_train)\n",
    "m.get_tree_metrics(y_train, y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9aee4708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX\n",
      "          0_predicted  1_predicted\n",
      "0_actual           94           16\n",
      "1_actual           21           47\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.85      0.84       110\n",
      "           1       0.75      0.69      0.72        68\n",
      "\n",
      "    accuracy                           0.79       178\n",
      "   macro avg       0.78      0.77      0.78       178\n",
      "weighted avg       0.79      0.79      0.79       178\n",
      "\n",
      "Accuracy: 0.7921348314606742\n",
      "\n",
      "True Positive Rate/Sensitivity/Recall/Power: 0.6911764705882353\n",
      "False Positive Rate/False Alarm Ratio/Fall-out: 0.14545454545454545\n",
      "True Negative Rate/Specificity/Selectivity: 0.8545454545454545\n",
      "False Negative Rate/Miss Rate: 0.3088235294117647\n",
      "\n",
      "Precision/PPV: 0.746031746031746\n",
      "F1 Score: 0.717557251908397\n",
      "\n",
      "Support (0): 68\n",
      "Support (1): 110\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(94, 16, 21, 47)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check vs validate\n",
    "y_pred_v1 = logit1.predict(X_validate)\n",
    "m.get_tree_metrics(y_validate, y_pred_v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d85d3616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now try only sending in survived, age, far, and pclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cdb30d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared df: (891, 4)\n",
      "\n",
      "Train: (534, 4)\n",
      "Validate: (178, 4)\n",
      "Test: (179, 4)\n"
     ]
    }
   ],
   "source": [
    "# remove all but survived, age, fare, and pclass\n",
    "train, validate, test = prep.split_function(df[['survived','pclass','age','fare']], target)\n",
    "train, validate, test = prep.impute_feature(train, validate, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b198bf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_validate, X_test, y_train, y_validate, y_test, baseline_accuracy = (\n",
    "    m.get_X_y_baseline(train, validate, test, target)\n",
    "    )\n",
    "# From review: another way is to set features1 = ['pclass','age','fare'], then\n",
    "# make X_train with [features1] (or features2, etc.)\n",
    "# rather than make new X_trains every time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "623c98d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make/fit/use the thing (LogisticRegression model)\n",
    "logit2 = LogisticRegression()\n",
    "logit2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8223e3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = logit2.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dca5d55c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX\n",
      "          0_predicted  1_predicted\n",
      "0_actual          290           39\n",
      "1_actual          115           90\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.88      0.79       329\n",
      "           1       0.70      0.44      0.54       205\n",
      "\n",
      "    accuracy                           0.71       534\n",
      "   macro avg       0.71      0.66      0.66       534\n",
      "weighted avg       0.71      0.71      0.69       534\n",
      "\n",
      "Accuracy: 0.7116104868913857\n",
      "\n",
      "True Positive Rate/Sensitivity/Recall/Power: 0.43902439024390244\n",
      "False Positive Rate/False Alarm Ratio/Fall-out: 0.11854103343465046\n",
      "True Negative Rate/Specificity/Selectivity: 0.8814589665653495\n",
      "False Negative Rate/Miss Rate: 0.5609756097560976\n",
      "\n",
      "Precision/PPV: 0.6976744186046512\n",
      "F1 Score: 0.5389221556886228\n",
      "\n",
      "Support (0): 205\n",
      "Support (1): 329\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(290, 39, 115, 90)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.get_tree_metrics(y_train, y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dbf19fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX\n",
      "          0_predicted  1_predicted\n",
      "0_actual           93           17\n",
      "1_actual           37           31\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.85      0.78       110\n",
      "           1       0.65      0.46      0.53        68\n",
      "\n",
      "    accuracy                           0.70       178\n",
      "   macro avg       0.68      0.65      0.65       178\n",
      "weighted avg       0.69      0.70      0.68       178\n",
      "\n",
      "Accuracy: 0.6966292134831461\n",
      "\n",
      "True Positive Rate/Sensitivity/Recall/Power: 0.45588235294117646\n",
      "False Positive Rate/False Alarm Ratio/Fall-out: 0.15454545454545454\n",
      "True Negative Rate/Specificity/Selectivity: 0.8454545454545455\n",
      "False Negative Rate/Miss Rate: 0.5441176470588235\n",
      "\n",
      "Precision/PPV: 0.6458333333333334\n",
      "F1 Score: 0.5344827586206896\n",
      "\n",
      "Support (0): 68\n",
      "Support (1): 110\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(93, 17, 37, 31)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check vs validate\n",
    "y_pred_v2 = logit2.predict(X_validate)\n",
    "m.get_tree_metrics(y_validate, y_pred_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ff0858f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6161048689138576"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8c0f2779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# so, sending in everything had an accuracy of .80/.80 (train/validate) and only sending in age, fare, and pclass \n",
    "# yields accuracy of .71/.70 which is still better than baseline, but not as good as sending in everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a7d7184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared df: (891, 5)\n",
      "\n",
      "Train: (534, 5)\n",
      "Validate: (178, 5)\n",
      "Test: (179, 5)\n"
     ]
    }
   ],
   "source": [
    "# now we will include sex\n",
    "# remove all but survived, age, fare, sex, and pclass\n",
    "train, validate, test = prep.split_function(df[['survived','pclass','age','fare', 'sex_male']], target)\n",
    "train, validate, test = prep.impute_feature(train, validate, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aeccfc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_validate, X_test, y_train, y_validate, y_test, baseline_accuracy = (\n",
    "    m.get_X_y_baseline(train, validate, test, target)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2925a3d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX\n",
      "          0_predicted  1_predicted\n",
      "0_actual          279           50\n",
      "1_actual           58          147\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.85      0.84       329\n",
      "           1       0.75      0.72      0.73       205\n",
      "\n",
      "    accuracy                           0.80       534\n",
      "   macro avg       0.79      0.78      0.78       534\n",
      "weighted avg       0.80      0.80      0.80       534\n",
      "\n",
      "Accuracy: 0.797752808988764\n",
      "\n",
      "True Positive Rate/Sensitivity/Recall/Power: 0.7170731707317073\n",
      "False Positive Rate/False Alarm Ratio/Fall-out: 0.1519756838905775\n",
      "True Negative Rate/Specificity/Selectivity: 0.8480243161094225\n",
      "False Negative Rate/Miss Rate: 0.28292682926829266\n",
      "\n",
      "Precision/PPV: 0.7461928934010152\n",
      "F1 Score: 0.7313432835820894\n",
      "\n",
      "Support (0): 205\n",
      "Support (1): 329\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(279, 50, 58, 147)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make/fit/use the thing (LogisticRegression model)\n",
    "logit3 = LogisticRegression()\n",
    "logit3.fit(X_train, y_train)\n",
    "y_pred3 = logit3.predict(X_train)\n",
    "m.get_tree_metrics(y_train, y_pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f78d0cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX\n",
      "          0_predicted  1_predicted\n",
      "0_actual           92           18\n",
      "1_actual           20           48\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83       110\n",
      "           1       0.73      0.71      0.72        68\n",
      "\n",
      "    accuracy                           0.79       178\n",
      "   macro avg       0.77      0.77      0.77       178\n",
      "weighted avg       0.79      0.79      0.79       178\n",
      "\n",
      "Accuracy: 0.7865168539325843\n",
      "\n",
      "True Positive Rate/Sensitivity/Recall/Power: 0.7058823529411765\n",
      "False Positive Rate/False Alarm Ratio/Fall-out: 0.16363636363636364\n",
      "True Negative Rate/Specificity/Selectivity: 0.8363636363636363\n",
      "False Negative Rate/Miss Rate: 0.29411764705882354\n",
      "\n",
      "Precision/PPV: 0.7272727272727273\n",
      "F1 Score: 0.7164179104477613\n",
      "\n",
      "Support (0): 68\n",
      "Support (1): 110\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(92, 18, 20, 48)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check vs validate\n",
    "y_pred_v3 = logit3.predict(X_validate)\n",
    "m.get_tree_metrics(y_validate, y_pred_v3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ecbc1b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# including sex gets the accuracy back up to .8/.79"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dd383259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared df: (891, 3)\n",
      "\n",
      "Train: (534, 3)\n",
      "Validate: (178, 3)\n",
      "Test: (179, 3)\n",
      "CONFUSION MATRIX\n",
      "          0_predicted  1_predicted\n",
      "0_actual          280           49\n",
      "1_actual           65          140\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.85      0.83       329\n",
      "           1       0.74      0.68      0.71       205\n",
      "\n",
      "    accuracy                           0.79       534\n",
      "   macro avg       0.78      0.77      0.77       534\n",
      "weighted avg       0.78      0.79      0.78       534\n",
      "\n",
      "Accuracy: 0.7865168539325843\n",
      "\n",
      "True Positive Rate/Sensitivity/Recall/Power: 0.6829268292682927\n",
      "False Positive Rate/False Alarm Ratio/Fall-out: 0.14893617021276595\n",
      "True Negative Rate/Specificity/Selectivity: 0.851063829787234\n",
      "False Negative Rate/Miss Rate: 0.3170731707317073\n",
      "\n",
      "Precision/PPV: 0.7407407407407407\n",
      "F1 Score: 0.7106598984771575\n",
      "\n",
      "Support (0): 205\n",
      "Support (1): 329\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(280, 49, 65, 140)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Next question: try out other combinations of features and models\n",
    "# I'm going to try one more: just sending in sex and alone\n",
    "train, validate, test = prep.split_function(df[['survived','alone', 'sex_male']], target)\n",
    "# train, validate, test = prep.impute_feature(train, validate, test) -- unneccessary\n",
    "X_train, X_validate, X_test, y_train, y_validate, y_test, baseline_accuracy = (\n",
    "    m.get_X_y_baseline(train, validate, test, target)\n",
    "    )\n",
    "# make/fit/use the thing (LogisticRegression model)\n",
    "logit4 = LogisticRegression()\n",
    "logit4.fit(X_train, y_train)\n",
    "y_pred4 = logit4.predict(X_train)\n",
    "m.get_tree_metrics(y_train, y_pred4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "17dbbba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX\n",
      "          0_predicted  1_predicted\n",
      "0_actual           94           16\n",
      "1_actual           20           48\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.85      0.84       110\n",
      "           1       0.75      0.71      0.73        68\n",
      "\n",
      "    accuracy                           0.80       178\n",
      "   macro avg       0.79      0.78      0.78       178\n",
      "weighted avg       0.80      0.80      0.80       178\n",
      "\n",
      "Accuracy: 0.797752808988764\n",
      "\n",
      "True Positive Rate/Sensitivity/Recall/Power: 0.7058823529411765\n",
      "False Positive Rate/False Alarm Ratio/Fall-out: 0.14545454545454545\n",
      "True Negative Rate/Specificity/Selectivity: 0.8545454545454545\n",
      "False Negative Rate/Miss Rate: 0.29411764705882354\n",
      "\n",
      "Precision/PPV: 0.75\n",
      "F1 Score: 0.7272727272727272\n",
      "\n",
      "Support (0): 68\n",
      "Support (1): 110\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(94, 16, 20, 48)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check vs validate\n",
    "y_pred_v4 = logit4.predict(X_validate)\n",
    "m.get_tree_metrics(y_validate, y_pred_v4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b4f33814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy is now .79/.80 (train/validate). Now I'm curious what the acc would be if I only send in sex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3a06c396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared df: (891, 2)\n",
      "\n",
      "Train: (534, 2)\n",
      "Validate: (178, 2)\n",
      "Test: (179, 2)\n",
      "CONFUSION MATRIX\n",
      "          0_predicted  1_predicted\n",
      "0_actual          280           49\n",
      "1_actual           65          140\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.85      0.83       329\n",
      "           1       0.74      0.68      0.71       205\n",
      "\n",
      "    accuracy                           0.79       534\n",
      "   macro avg       0.78      0.77      0.77       534\n",
      "weighted avg       0.78      0.79      0.78       534\n",
      "\n",
      "Accuracy: 0.7865168539325843\n",
      "\n",
      "True Positive Rate/Sensitivity/Recall/Power: 0.6829268292682927\n",
      "False Positive Rate/False Alarm Ratio/Fall-out: 0.14893617021276595\n",
      "True Negative Rate/Specificity/Selectivity: 0.851063829787234\n",
      "False Negative Rate/Miss Rate: 0.3170731707317073\n",
      "\n",
      "Precision/PPV: 0.7407407407407407\n",
      "F1 Score: 0.7106598984771575\n",
      "\n",
      "Support (0): 205\n",
      "Support (1): 329\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(280, 49, 65, 140)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I'm going to try one more: just sending in sex \n",
    "train, validate, test = prep.split_function(df[['survived', 'sex_male']], target)\n",
    "# train, validate, test = prep.impute_feature(train, validate, test) -- unneccessary\n",
    "X_train, X_validate, X_test, y_train, y_validate, y_test, baseline_accuracy = (\n",
    "    m.get_X_y_baseline(train, validate, test, target)\n",
    "    )\n",
    "# make/fit/use the thing (LogisticRegression model)\n",
    "logit5 = LogisticRegression()\n",
    "logit5.fit(X_train, y_train)\n",
    "y_pred5 = logit5.predict(X_train)\n",
    "m.get_tree_metrics(y_train, y_pred5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cd2f0db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX\n",
      "          0_predicted  1_predicted\n",
      "0_actual           94           16\n",
      "1_actual           20           48\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.85      0.84       110\n",
      "           1       0.75      0.71      0.73        68\n",
      "\n",
      "    accuracy                           0.80       178\n",
      "   macro avg       0.79      0.78      0.78       178\n",
      "weighted avg       0.80      0.80      0.80       178\n",
      "\n",
      "Accuracy: 0.797752808988764\n",
      "\n",
      "True Positive Rate/Sensitivity/Recall/Power: 0.7058823529411765\n",
      "False Positive Rate/False Alarm Ratio/Fall-out: 0.14545454545454545\n",
      "True Negative Rate/Specificity/Selectivity: 0.8545454545454545\n",
      "False Negative Rate/Miss Rate: 0.29411764705882354\n",
      "\n",
      "Precision/PPV: 0.75\n",
      "F1 Score: 0.7272727272727272\n",
      "\n",
      "Support (0): 68\n",
      "Support (1): 110\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(94, 16, 20, 48)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check vs validate\n",
    "y_pred_v5 = logit5.predict(X_validate)\n",
    "m.get_tree_metrics(y_validate, y_pred_v5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b02dcab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HA! it's .79/.80 (train/validate); justing using sex is almost as good as sending in everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "12534ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So now, I'll check these models vs validate\n",
    "# I went back and added get_tree_metrics to the code above but called it with validate\n",
    "#... looks like the best model is the one where I sent in everything, i.e. #1  \n",
    "# Now I'll run that model on the test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b029b4b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared df: (891, 10)\n",
      "\n",
      "Train: (534, 10)\n",
      "Validate: (178, 10)\n",
      "Test: (179, 10)\n",
      "CONFUSION MATRIX\n",
      "          0_predicted  1_predicted\n",
      "0_actual           96           14\n",
      "1_actual           22           47\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.87      0.84       110\n",
      "           1       0.77      0.68      0.72        69\n",
      "\n",
      "    accuracy                           0.80       179\n",
      "   macro avg       0.79      0.78      0.78       179\n",
      "weighted avg       0.80      0.80      0.80       179\n",
      "\n",
      "Accuracy: 0.7988826815642458\n",
      "\n",
      "True Positive Rate/Sensitivity/Recall/Power: 0.6811594202898551\n",
      "False Positive Rate/False Alarm Ratio/Fall-out: 0.12727272727272726\n",
      "True Negative Rate/Specificity/Selectivity: 0.8727272727272727\n",
      "False Negative Rate/Miss Rate: 0.3188405797101449\n",
      "\n",
      "Precision/PPV: 0.7704918032786885\n",
      "F1 Score: 0.7230769230769231\n",
      "\n",
      "Support (0): 69\n",
      "Support (1): 110\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(96, 14, 22, 47)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, validate, test = prep.split_function(df, target)\n",
    "train, validate, test = prep.impute_feature(train, validate, test)\n",
    "X_train, X_validate, X_test, y_train, y_validate, y_test, baseline_accuracy = (\n",
    "    m.get_X_y_baseline(train, validate, test, target)\n",
    "    )\n",
    "logit1 = LogisticRegression()\n",
    "logit1.fit(X_train, y_train)\n",
    "y_pred1 = logit1.predict(X_test)\n",
    "m.get_tree_metrics(y_test, y_pred1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5b0004",
   "metadata": {},
   "source": [
    "### running best model on test data yields accuracy of .8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8daa0bf6",
   "metadata": {},
   "source": [
    "## Bonus1 How do different strategies for handling the missing values in the age column affect model performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2d0c33ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared df: (891, 10)\n",
      "\n",
      "Train: (534, 10)\n",
      "Validate: (178, 10)\n",
      "Test: (179, 10)\n",
      "CONFUSION MATRIX\n",
      "          0_predicted  1_predicted\n",
      "0_actual           94           16\n",
      "1_actual           23           46\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.85      0.83       110\n",
      "           1       0.74      0.67      0.70        69\n",
      "\n",
      "    accuracy                           0.78       179\n",
      "   macro avg       0.77      0.76      0.77       179\n",
      "weighted avg       0.78      0.78      0.78       179\n",
      "\n",
      "Accuracy: 0.7821229050279329\n",
      "\n",
      "True Positive Rate/Sensitivity/Recall/Power: 0.6666666666666666\n",
      "False Positive Rate/False Alarm Ratio/Fall-out: 0.14545454545454545\n",
      "True Negative Rate/Specificity/Selectivity: 0.8545454545454545\n",
      "False Negative Rate/Miss Rate: 0.3333333333333333\n",
      "\n",
      "Precision/PPV: 0.7419354838709677\n",
      "F1 Score: 0.7022900763358778\n",
      "\n",
      "Support (0): 69\n",
      "Support (1): 110\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(94, 16, 23, 46)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I'll try mean first. mean and median were very close, so I don't expect much difference.\n",
    "train, validate, test = prep.split_function(df, target)\n",
    "train, validate, test = prep.impute_feature(train, validate, test, strat='mean')\n",
    "X_train, X_validate, X_test, y_train, y_validate, y_test, baseline_accuracy = (\n",
    "    m.get_X_y_baseline(train, validate, test, target)\n",
    "    )\n",
    "logit1 = LogisticRegression()\n",
    "logit1.fit(X_train, y_train)\n",
    "y_pred1 = logit1.predict(X_test)\n",
    "m.get_tree_metrics(y_test, y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6c9c800c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean brought the accuracy down to .78"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b69372b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared df: (891, 10)\n",
      "\n",
      "Train: (534, 10)\n",
      "Validate: (178, 10)\n",
      "Test: (179, 10)\n",
      "CONFUSION MATRIX\n",
      "          0_predicted  1_predicted\n",
      "0_actual           93           17\n",
      "1_actual           20           49\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.85      0.83       110\n",
      "           1       0.74      0.71      0.73        69\n",
      "\n",
      "    accuracy                           0.79       179\n",
      "   macro avg       0.78      0.78      0.78       179\n",
      "weighted avg       0.79      0.79      0.79       179\n",
      "\n",
      "Accuracy: 0.7932960893854749\n",
      "\n",
      "True Positive Rate/Sensitivity/Recall/Power: 0.7101449275362319\n",
      "False Positive Rate/False Alarm Ratio/Fall-out: 0.15454545454545454\n",
      "True Negative Rate/Specificity/Selectivity: 0.8454545454545455\n",
      "False Negative Rate/Miss Rate: 0.2898550724637681\n",
      "\n",
      "Precision/PPV: 0.7424242424242424\n",
      "F1 Score: 0.725925925925926\n",
      "\n",
      "Support (0): 69\n",
      "Support (1): 110\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(93, 17, 20, 49)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# next I'll try mode\n",
    "train, validate, test = prep.split_function(df, target)\n",
    "train, validate, test = prep.impute_feature(train, validate, test, strat=\"most_frequent\")\n",
    "X_train, X_validate, X_test, y_train, y_validate, y_test, baseline_accuracy = (\n",
    "    m.get_X_y_baseline(train, validate, test, target)\n",
    "    )\n",
    "logit1 = LogisticRegression()\n",
    "logit1.fit(X_train, y_train)\n",
    "y_pred1 = logit1.predict(X_test)\n",
    "m.get_tree_metrics(y_test, y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "06056bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# most_frequent dropped the accuracy to .79"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4416821b",
   "metadata": {},
   "source": [
    "## Bonus2: How do different strategies for encoding sex affect model performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0f5183fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I don't understand what other strategies there might be for encoding a category with a 0 or a 1 for values.\n",
    "# I suppose you could make it \"sex_female\" instead of \"sex_male\", but that should have no effect. I'll try it\n",
    "# if I get time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fa1712",
   "metadata": {},
   "source": [
    "## Bonus3: \n",
    "\n",
    "scikit-learn's LogisticRegression classifier is actually applying a regularization penalty to the coefficients by default. This penalty causes the magnitude of the coefficients in the resulting model to be smaller than they otherwise would be. This value can be modified with the C hyper parameter. Small values of C correspond to a larger penalty, and large values of C correspond to a smaller penalty.\n",
    "\n",
    "    Try out the following values for C and note how the coefficients and the model's performance on both the dataset it was trained on and on the validate split are affected. \n",
    "    \n",
    "        C=.01,.1,1,10,100,1000\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c5d591f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv file found and read\n"
     ]
    }
   ],
   "source": [
    "df = acq.get_titanic_data()\n",
    "df = prep.prep_titanic_2(df) #keeping age\n",
    "df = prep.prep_titanic_for_model(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "55bd940f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared df: (891, 10)\n",
      "\n",
      "Train: (534, 10)\n",
      "Validate: (178, 10)\n",
      "Test: (179, 10)\n"
     ]
    }
   ],
   "source": [
    "target = 'survived'\n",
    "train, test, validate = prep.split_function(df, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "898403ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, validate = prep.impute_feature(train, test, validate, feature='age', strat='median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d1d61330",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_validate, X_test, y_train, y_validate, y_test, baseline_accuracy = (\n",
    "    m.get_X_y_baseline(train, validate, test, target)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "650b3c00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C</td>\n",
       "      <td>train_acc</td>\n",
       "      <td>val_acc</td>\n",
       "      <td>coef_pclass</td>\n",
       "      <td>coef_age</td>\n",
       "      <td>coef_sibsp</td>\n",
       "      <td>coef_parch</td>\n",
       "      <td>coef_fare</td>\n",
       "      <td>coef_alone</td>\n",
       "      <td>coef_sex_male</td>\n",
       "      <td>coef_embarked_Q</td>\n",
       "      <td>coef_embarked_S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.737828</td>\n",
       "      <td>0.703911</td>\n",
       "      <td>-0.247513</td>\n",
       "      <td>-0.026858</td>\n",
       "      <td>-0.132036</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.015939</td>\n",
       "      <td>-0.096574</td>\n",
       "      <td>-0.441744</td>\n",
       "      <td>0.052507</td>\n",
       "      <td>-0.090043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.793296</td>\n",
       "      <td>-0.786977</td>\n",
       "      <td>-0.033065</td>\n",
       "      <td>-0.226057</td>\n",
       "      <td>-0.052152</td>\n",
       "      <td>0.006609</td>\n",
       "      <td>-0.325945</td>\n",
       "      <td>-1.653963</td>\n",
       "      <td>0.328944</td>\n",
       "      <td>-0.211307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.799625</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>-1.089572</td>\n",
       "      <td>-0.039985</td>\n",
       "      <td>-0.268472</td>\n",
       "      <td>-0.142915</td>\n",
       "      <td>0.004208</td>\n",
       "      <td>-0.328858</td>\n",
       "      <td>-2.441633</td>\n",
       "      <td>1.008116</td>\n",
       "      <td>-0.084958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.801498</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>-1.178705</td>\n",
       "      <td>-0.038797</td>\n",
       "      <td>-0.271719</td>\n",
       "      <td>-0.130528</td>\n",
       "      <td>0.003651</td>\n",
       "      <td>-0.336175</td>\n",
       "      <td>-2.552949</td>\n",
       "      <td>1.185038</td>\n",
       "      <td>-0.074542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.801498</td>\n",
       "      <td>0.804469</td>\n",
       "      <td>-1.154457</td>\n",
       "      <td>-0.042974</td>\n",
       "      <td>-0.356735</td>\n",
       "      <td>-0.190279</td>\n",
       "      <td>0.004649</td>\n",
       "      <td>-0.442668</td>\n",
       "      <td>-2.628522</td>\n",
       "      <td>1.09627</td>\n",
       "      <td>0.011479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.807116</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>-1.200483</td>\n",
       "      <td>-0.041705</td>\n",
       "      <td>-0.315424</td>\n",
       "      <td>-0.204639</td>\n",
       "      <td>0.003467</td>\n",
       "      <td>-0.547029</td>\n",
       "      <td>-2.614819</td>\n",
       "      <td>1.110982</td>\n",
       "      <td>-0.081801</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0          1         2            3         4           5           6   \\\n",
       "0       C  train_acc   val_acc  coef_pclass  coef_age  coef_sibsp  coef_parch   \n",
       "0    0.01   0.737828  0.703911    -0.247513 -0.026858   -0.132036    0.019531   \n",
       "0     0.1   0.808989  0.793296    -0.786977 -0.033065   -0.226057   -0.052152   \n",
       "0     1.0   0.799625  0.798883    -1.089572 -0.039985   -0.268472   -0.142915   \n",
       "0    10.0   0.801498  0.798883    -1.178705 -0.038797   -0.271719   -0.130528   \n",
       "0   100.0   0.801498  0.804469    -1.154457 -0.042974   -0.356735   -0.190279   \n",
       "0  1000.0   0.807116  0.798883    -1.200483 -0.041705   -0.315424   -0.204639   \n",
       "\n",
       "          7           8              9                10               11  \n",
       "0  coef_fare  coef_alone  coef_sex_male  coef_embarked_Q  coef_embarked_S  \n",
       "0   0.015939   -0.096574      -0.441744         0.052507        -0.090043  \n",
       "0   0.006609   -0.325945      -1.653963         0.328944        -0.211307  \n",
       "0   0.004208   -0.328858      -2.441633         1.008116        -0.084958  \n",
       "0   0.003651   -0.336175      -2.552949         1.185038        -0.074542  \n",
       "0   0.004649   -0.442668      -2.628522          1.09627         0.011479  \n",
       "0   0.003467   -0.547029      -2.614819         1.110982        -0.081801  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the LogisticRegression model with different c values \n",
    "# initialize range of C values and a dictionary to store things in\n",
    "C_values = [.01, .1, 1, 10, 100, 1000]\n",
    "results = []\n",
    "cols = ['C','train_acc','val_acc']\n",
    "coef_cols = ['coef_' + c for c in X_train.columns]\n",
    "results_df = pd.DataFrame(cols + coef_cols).T\n",
    "\n",
    "for x in C_values:\n",
    "    logit = LogisticRegression(C=x)\n",
    "    logit.fit(X_train, y_train)\n",
    "#    y_pred = logit.predict(X_train)\n",
    "#    m.get_tree_metrics(y_test, y_pred)\n",
    "    train_acc = logit.score(X_train, y_train)\n",
    "    val_acc = logit.score(X_validate, y_validate)\n",
    "\n",
    "    test = np.array([x, train_acc, val_acc])\n",
    "    test_coef = logit.coef_\n",
    "    combo_array = np.concatenate((test, test_coef[0]))\n",
    "    new_df = pd.DataFrame(combo_array)\n",
    "    results_df = pd.concat((results_df, new_df.T), axis=0)\n",
    "\n",
    "#     print(f'For C = {x}, the train/validate accuracy is {train_acc} / {val_acc}.')\n",
    "#     print(f'AND, the model coefficients are: {logit.coef_}.')\n",
    "    \n",
    "# print out dataframe with C values, train and val accuracies, and the coefficients for each feature    \n",
    "results_df    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6be2696",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
